Learning rate 0.01, only 2 iterations of the network, here are 60 steps, good convergence:

```
size (leaves): 2944 2906 37 1
0.7789340019226074  seconds
initial loss  0.035475712  computed in  0.5853939056396484  seconds
about to compute gradient
19.293214797973633  seconds to compute gradient
0.0020284652709960938  seconds to apply mask to gradient
17.716118335723877  seconds to compute optimizer update
0.33422422409057617  seconds to apply optimizer update
0.1327824592590332  seconds to pickle the checkpoint
step: 0 loss: 0.0354757122695446
about to compute gradient
19.138338088989258  seconds to compute gradient
0.0029914379119873047  seconds to apply mask to gradient
0.68670654296875  seconds to compute optimizer update
0.3168156147003174  seconds to apply optimizer update
0.08335614204406738  seconds to pickle the checkpoint
step: 1 loss: 0.026163488626480103
about to compute gradient
18.732919931411743  seconds to compute gradient
0.0021791458129882812  seconds to apply mask to gradient
0.687671422958374  seconds to compute optimizer update
0.31440091133117676  seconds to apply optimizer update
0.13613057136535645  seconds to pickle the checkpoint
step: 2 loss: 0.018400786444544792
about to compute gradient
18.9794921875  seconds to compute gradient
0.0020329952239990234  seconds to apply mask to gradient
0.720984935760498  seconds to compute optimizer update
0.3170125484466553  seconds to apply optimizer update
0.0866096019744873  seconds to pickle the checkpoint
step: 3 loss: 0.012148668058216572
about to compute gradient
19.000873804092407  seconds to compute gradient
0.0020263195037841797  seconds to apply mask to gradient
0.6716735363006592  seconds to compute optimizer update
0.3175547122955322  seconds to apply optimizer update
0.08353090286254883  seconds to pickle the checkpoint
step: 4 loss: 0.007514637429267168
about to compute gradient
18.973819732666016  seconds to compute gradient
0.0019989013671875  seconds to apply mask to gradient
0.6852257251739502  seconds to compute optimizer update
0.3215157985687256  seconds to apply optimizer update
0.08600997924804688  seconds to pickle the checkpoint
step: 5 loss: 0.00431094178929925
about to compute gradient
18.957716464996338  seconds to compute gradient
0.002956390380859375  seconds to apply mask to gradient
0.6870474815368652  seconds to compute optimizer update
0.3183917999267578  seconds to apply optimizer update
0.08764147758483887  seconds to pickle the checkpoint
step: 6 loss: 0.002259601606056094
about to compute gradient
18.897271156311035  seconds to compute gradient
0.0020339488983154297  seconds to apply mask to gradient
0.6759889125823975  seconds to compute optimizer update
0.3220491409301758  seconds to apply optimizer update
0.08635354042053223  seconds to pickle the checkpoint
step: 7 loss: 0.0013064906233921647
about to compute gradient
18.786797046661377  seconds to compute gradient
0.001998424530029297  seconds to apply mask to gradient
0.7262425422668457  seconds to compute optimizer update
0.3140418529510498  seconds to apply optimizer update
0.08491826057434082  seconds to pickle the checkpoint
step: 8 loss: 0.0014113113284111023
about to compute gradient
19.132558584213257  seconds to compute gradient
0.0017061233520507812  seconds to apply mask to gradient
0.6831398010253906  seconds to compute optimizer update
0.32276439666748047  seconds to apply optimizer update
0.08869671821594238  seconds to pickle the checkpoint
step: 9 loss: 0.002200515242293477
about to compute gradient
19.07166290283203  seconds to compute gradient
0.0019173622131347656  seconds to apply mask to gradient
0.6899235248565674  seconds to compute optimizer update
0.3267083168029785  seconds to apply optimizer update
0.08817815780639648  seconds to pickle the checkpoint
step: 10 loss: 0.0030318493954837322
about to compute gradient
19.290691137313843  seconds to compute gradient
0.001992464065551758  seconds to apply mask to gradient
0.6829254627227783  seconds to compute optimizer update
0.31689929962158203  seconds to apply optimizer update
0.08811020851135254  seconds to pickle the checkpoint
step: 11 loss: 0.0034678843803703785
about to compute gradient
18.914902210235596  seconds to compute gradient
0.0019965171813964844  seconds to apply mask to gradient
0.6782755851745605  seconds to compute optimizer update
0.3159065246582031  seconds to apply optimizer update
0.13126778602600098  seconds to pickle the checkpoint
step: 12 loss: 0.003403319278731942
about to compute gradient
19.055140733718872  seconds to compute gradient
0.0038766860961914062  seconds to apply mask to gradient
0.7114243507385254  seconds to compute optimizer update
0.3185696601867676  seconds to apply optimizer update
0.08597612380981445  seconds to pickle the checkpoint
step: 13 loss: 0.002903914311900735
about to compute gradient
18.922083139419556  seconds to compute gradient
0.0015652179718017578  seconds to apply mask to gradient
0.6882534027099609  seconds to compute optimizer update
0.3136332035064697  seconds to apply optimizer update
0.08530759811401367  seconds to pickle the checkpoint
step: 14 loss: 0.0021552331745624542
about to compute gradient
18.970835208892822  seconds to compute gradient
0.0018732547760009766  seconds to apply mask to gradient
0.6673364639282227  seconds to compute optimizer update
0.31766438484191895  seconds to apply optimizer update
0.08911967277526855  seconds to pickle the checkpoint
step: 15 loss: 0.0013782086316496134
about to compute gradient
18.831491231918335  seconds to compute gradient
0.0020258426666259766  seconds to apply mask to gradient
0.6806759834289551  seconds to compute optimizer update
0.3170125484466553  seconds to apply optimizer update
0.08646345138549805  seconds to pickle the checkpoint
step: 16 loss: 0.0007399263558909297
about to compute gradient
18.86366868019104  seconds to compute gradient
0.0029981136322021484  seconds to apply mask to gradient
0.6986806392669678  seconds to compute optimizer update
0.32060813903808594  seconds to apply optimizer update
0.0866093635559082  seconds to pickle the checkpoint
step: 17 loss: 0.00032281744643114507
about to compute gradient
19.029839515686035  seconds to compute gradient
0.0019583702087402344  seconds to apply mask to gradient
0.6785955429077148  seconds to compute optimizer update
0.3148152828216553  seconds to apply optimizer update
0.0862727165222168  seconds to pickle the checkpoint
step: 18 loss: 0.00013792651589028537
about to compute gradient
18.63314700126648  seconds to compute gradient
0.0030248165130615234  seconds to apply mask to gradient
0.6728665828704834  seconds to compute optimizer update
0.31665515899658203  seconds to apply optimizer update
0.13603734970092773  seconds to pickle the checkpoint
step: 19 loss: 0.00014717079466208816
about to compute gradient
18.79073476791382  seconds to compute gradient
0.0020322799682617188  seconds to apply mask to gradient
0.7331664562225342  seconds to compute optimizer update
0.31694531440734863  seconds to apply optimizer update
0.08736157417297363  seconds to pickle the checkpoint
step: 20 loss: 0.00028657043003477156
about to compute gradient
19.021153926849365  seconds to compute gradient
0.0030236244201660156  seconds to apply mask to gradient
0.6697795391082764  seconds to compute optimizer update
0.320659875869751  seconds to apply optimizer update
0.08330988883972168  seconds to pickle the checkpoint
step: 21 loss: 0.0004809727834071964
about to compute gradient
18.855852127075195  seconds to compute gradient
0.001995563507080078  seconds to apply mask to gradient
0.673332691192627  seconds to compute optimizer update
0.3259248733520508  seconds to apply optimizer update
0.09484410285949707  seconds to pickle the checkpoint
step: 22 loss: 0.0006583115318790078
about to compute gradient
18.890756607055664  seconds to compute gradient
0.0019910335540771484  seconds to apply mask to gradient
0.6881799697875977  seconds to compute optimizer update
0.3181641101837158  seconds to apply optimizer update
0.11291933059692383  seconds to pickle the checkpoint
step: 23 loss: 0.0007675852393731475
about to compute gradient
18.880193948745728  seconds to compute gradient
0.002303600311279297  seconds to apply mask to gradient
0.6800785064697266  seconds to compute optimizer update
0.31744885444641113  seconds to apply optimizer update
0.08655405044555664  seconds to pickle the checkpoint
step: 24 loss: 0.0007867505773901939
about to compute gradient
18.876424074172974  seconds to compute gradient
0.0020284652709960938  seconds to apply mask to gradient
0.6859695911407471  seconds to compute optimizer update
0.3135404586791992  seconds to apply optimizer update
0.0845799446105957  seconds to pickle the checkpoint
step: 25 loss: 0.0007201267872005701
about to compute gradient
18.849894523620605  seconds to compute gradient
0.0021414756774902344  seconds to apply mask to gradient
0.6823790073394775  seconds to compute optimizer update
0.3203907012939453  seconds to apply optimizer update
0.08536005020141602  seconds to pickle the checkpoint
step: 26 loss: 0.0005904420977458358
about to compute gradient
18.95861291885376  seconds to compute gradient
0.0019960403442382812  seconds to apply mask to gradient
0.680206298828125  seconds to compute optimizer update
0.3152005672454834  seconds to apply optimizer update
0.08572602272033691  seconds to pickle the checkpoint
step: 27 loss: 0.00042936409590765834
about to compute gradient
18.74246644973755  seconds to compute gradient
0.002026081085205078  seconds to apply mask to gradient
0.6757938861846924  seconds to compute optimizer update
0.31642746925354004  seconds to apply optimizer update
0.0872342586517334  seconds to pickle the checkpoint
step: 28 loss: 0.0002690087421797216
about to compute gradient
18.89453363418579  seconds to compute gradient
0.002062559127807617  seconds to apply mask to gradient
0.6930806636810303  seconds to compute optimizer update
0.31618165969848633  seconds to apply optimizer update
0.08868217468261719  seconds to pickle the checkpoint
step: 29 loss: 0.00013565627159550786
>>> for n_step in range(30):
...     changing_output, opt_state, loss = step(changing_output, opt_state)
...     start_time = time.time()
...     with open('changing_output.pkl', 'wb') as f:
...         pickle.dump(changing_output, f)
...     with open('opt_state.pkl', 'wb') as f:
...         pickle.dump(opt_state, f)
...     print(time.time()-start_time, " seconds to pickle the checkpoint")
...     print(f'step: {n_step} loss: {loss}')
...
about to compute gradient
19.590819597244263  seconds to compute gradient
0.0020313262939453125  seconds to apply mask to gradient
0.6895027160644531  seconds to compute optimizer update
0.31601619720458984  seconds to apply optimizer update
0.08776259422302246  seconds to pickle the checkpoint
step: 0 loss: 4.599140083882958e-05
about to compute gradient
19.093367099761963  seconds to compute gradient
0.0019910335540771484  seconds to apply mask to gradient
0.6959700584411621  seconds to compute optimizer update
0.3138759136199951  seconds to apply optimizer update
0.08415484428405762  seconds to pickle the checkpoint
step: 1 loss: 5.737433184549445e-06
about to compute gradient
22.10770297050476  seconds to compute gradient
0.002989530563354492  seconds to apply mask to gradient
0.803682804107666  seconds to compute optimizer update
0.3824918270111084  seconds to apply optimizer update
0.17954444885253906  seconds to pickle the checkpoint
step: 2 loss: 1.0678832950361539e-05
about to compute gradient
21.10969638824463  seconds to compute gradient
0.0029637813568115234  seconds to apply mask to gradient
0.7734708786010742  seconds to compute optimizer update
0.32320117950439453  seconds to apply optimizer update
0.08905172348022461  seconds to pickle the checkpoint
step: 3 loss: 4.742630699183792e-05
about to compute gradient
19.660014629364014  seconds to compute gradient
0.0020265579223632812  seconds to apply mask to gradient
0.6992781162261963  seconds to compute optimizer update
0.3226888179779053  seconds to apply optimizer update
0.08515620231628418  seconds to pickle the checkpoint
step: 4 loss: 9.795540245249867e-05
about to compute gradient
19.825724124908447  seconds to compute gradient
0.0019826889038085938  seconds to apply mask to gradient
0.7398166656494141  seconds to compute optimizer update
0.3300158977508545  seconds to apply optimizer update
0.15489912033081055  seconds to pickle the checkpoint
step: 5 loss: 0.00014456109784077853
about to compute gradient
20.297054052352905  seconds to compute gradient
0.001996278762817383  seconds to apply mask to gradient
0.717442512512207  seconds to compute optimizer update
0.32288408279418945  seconds to apply optimizer update
0.1335582733154297  seconds to pickle the checkpoint
step: 6 loss: 0.000174226937815547
about to compute gradient
19.347107887268066  seconds to compute gradient
0.000997781753540039  seconds to apply mask to gradient
0.6966462135314941  seconds to compute optimizer update
0.33576250076293945  seconds to apply optimizer update
0.13386297225952148  seconds to pickle the checkpoint
step: 7 loss: 0.00018103205366060138
about to compute gradient
19.271125078201294  seconds to compute gradient
0.0010340213775634766  seconds to apply mask to gradient
0.7079346179962158  seconds to compute optimizer update
0.32558488845825195  seconds to apply optimizer update
0.13129782676696777  seconds to pickle the checkpoint
step: 8 loss: 0.00016600820526946336
about to compute gradient
19.39151120185852  seconds to compute gradient
0.0019953250885009766  seconds to apply mask to gradient
0.7009906768798828  seconds to compute optimizer update
0.3233494758605957  seconds to apply optimizer update
0.13123345375061035  seconds to pickle the checkpoint
step: 9 loss: 0.00013552674499806017
about to compute gradient
19.356195211410522  seconds to compute gradient
0.0020334720611572266  seconds to apply mask to gradient
0.7117917537689209  seconds to compute optimizer update
0.3230602741241455  seconds to apply optimizer update
0.13649559020996094  seconds to pickle the checkpoint
step: 10 loss: 9.819339902605861e-05
about to compute gradient
19.42587947845459  seconds to compute gradient
0.001959562301635742  seconds to apply mask to gradient
0.6898558139801025  seconds to compute optimizer update
0.3187110424041748  seconds to apply optimizer update
0.14037656784057617  seconds to pickle the checkpoint
step: 11 loss: 6.227995618246496e-05
about to compute gradient
19.260783195495605  seconds to compute gradient
0.001996278762817383  seconds to apply mask to gradient
0.6850552558898926  seconds to compute optimizer update
0.3233819007873535  seconds to apply optimizer update
0.1350083351135254  seconds to pickle the checkpoint
step: 12 loss: 3.382264185347594e-05
about to compute gradient
19.2659113407135  seconds to compute gradient
0.0019485950469970703  seconds to apply mask to gradient
0.7078604698181152  seconds to compute optimizer update
0.3199427127838135  seconds to apply optimizer update
0.1363997459411621  seconds to pickle the checkpoint
step: 13 loss: 1.5849678675294854e-05
about to compute gradient
19.20763373374939  seconds to compute gradient
0.0020020008087158203  seconds to apply mask to gradient
0.7300395965576172  seconds to compute optimizer update
0.3212006092071533  seconds to apply optimizer update
0.13521051406860352  seconds to pickle the checkpoint
step: 14 loss: 8.442830221611075e-06
about to compute gradient
19.314616441726685  seconds to compute gradient
0.0020325183868408203  seconds to apply mask to gradient
0.7141013145446777  seconds to compute optimizer update
0.3224828243255615  seconds to apply optimizer update
0.13653135299682617  seconds to pickle the checkpoint
step: 15 loss: 9.799421604839154e-06
about to compute gradient
19.416043519973755  seconds to compute gradient
0.0020287036895751953  seconds to apply mask to gradient
0.6834931373596191  seconds to compute optimizer update
0.32625651359558105  seconds to apply optimizer update
0.13423562049865723  seconds to pickle the checkpoint
step: 16 loss: 1.6973019228316844e-05
about to compute gradient
19.235044956207275  seconds to compute gradient
0.0022666454315185547  seconds to apply mask to gradient
0.6922907829284668  seconds to compute optimizer update
0.32485318183898926  seconds to apply optimizer update
0.13377928733825684  seconds to pickle the checkpoint
step: 17 loss: 2.6673031243262812e-05
about to compute gradient
19.265795946121216  seconds to compute gradient
0.0019969940185546875  seconds to apply mask to gradient
0.7050888538360596  seconds to compute optimizer update
0.3236246109008789  seconds to apply optimizer update
0.1331632137298584  seconds to pickle the checkpoint
step: 18 loss: 3.5900397051591426e-05
about to compute gradient
19.513681411743164  seconds to compute gradient
0.0020999908447265625  seconds to apply mask to gradient
0.7125518321990967  seconds to compute optimizer update
0.32868242263793945  seconds to apply optimizer update
0.13070368766784668  seconds to pickle the checkpoint
step: 19 loss: 4.2361840314697474e-05
about to compute gradient
19.338971614837646  seconds to compute gradient
0.001001119613647461  seconds to apply mask to gradient
0.6936960220336914  seconds to compute optimizer update
0.31568288803100586  seconds to apply optimizer update
0.13241124153137207  seconds to pickle the checkpoint
step: 20 loss: 4.469383566174656e-05
about to compute gradient
19.280699491500854  seconds to compute gradient
0.001995086669921875  seconds to apply mask to gradient
0.7079160213470459  seconds to compute optimizer update
0.3268253803253174  seconds to apply optimizer update
0.1373295783996582  seconds to pickle the checkpoint
step: 21 loss: 4.253018050803803e-05
about to compute gradient
19.396090507507324  seconds to compute gradient
0.0029876232147216797  seconds to apply mask to gradient
0.6954927444458008  seconds to compute optimizer update
0.3223860263824463  seconds to apply optimizer update
0.13547062873840332  seconds to pickle the checkpoint
step: 22 loss: 3.6439450923353434e-05
about to compute gradient
19.126989126205444  seconds to compute gradient
0.002998828887939453  seconds to apply mask to gradient
0.6840593814849854  seconds to compute optimizer update
0.32758450508117676  seconds to apply optimizer update
0.1378026008605957  seconds to pickle the checkpoint
step: 23 loss: 2.7736819902202114e-05
about to compute gradient
19.32681918144226  seconds to compute gradient
0.0010352134704589844  seconds to apply mask to gradient
0.709930419921875  seconds to compute optimizer update
0.31862354278564453  seconds to apply optimizer update
0.13120102882385254  seconds to pickle the checkpoint
step: 24 loss: 1.818732744141016e-05
about to compute gradient
19.236315965652466  seconds to compute gradient
0.0019860267639160156  seconds to apply mask to gradient
0.7058634757995605  seconds to compute optimizer update
0.323822021484375  seconds to apply optimizer update
0.13853669166564941  seconds to pickle the checkpoint
step: 25 loss: 9.624853191780858e-06
about to compute gradient
19.13528323173523  seconds to compute gradient
0.0019872188568115234  seconds to apply mask to gradient
0.6928369998931885  seconds to compute optimizer update
0.3253350257873535  seconds to apply optimizer update
0.1326615810394287  seconds to pickle the checkpoint
step: 26 loss: 3.549018174453522e-06
about to compute gradient
19.36052656173706  seconds to compute gradient
0.001994609832763672  seconds to apply mask to gradient
0.7057015895843506  seconds to compute optimizer update
0.3151741027832031  seconds to apply optimizer update
0.12975072860717773  seconds to pickle the checkpoint
step: 27 loss: 8.003764833119931e-07
about to compute gradient
19.160517930984497  seconds to compute gradient
0.001998424530029297  seconds to apply mask to gradient
0.6800088882446289  seconds to compute optimizer update
0.32692575454711914  seconds to apply optimizer update
0.13410091400146484  seconds to pickle the checkpoint
step: 28 loss: 1.2989762581128161e-06
about to compute gradient
19.114811897277832  seconds to compute gradient
0.0020270347595214844  seconds to apply mask to gradient
0.6990368366241455  seconds to compute optimizer update
0.32794690132141113  seconds to apply optimizer update
0.13082551956176758  seconds to pickle the checkpoint
step: 29 loss: 4.18999070461723e-06
>>>
```
