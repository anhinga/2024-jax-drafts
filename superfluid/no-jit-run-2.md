Learning rate 0.01, only 2 iterations of the network, here are 60 steps, good convergence:

```
size (leaves): 2944 2906 37 1
0.7789340019226074  seconds
initial loss  0.035475712  computed in  0.5853939056396484  seconds
about to compute gradient
19.293214797973633  seconds to compute gradient
0.0020284652709960938  seconds to apply mask to gradient
17.716118335723877  seconds to compute optimizer update
0.33422422409057617  seconds to apply optimizer update
0.1327824592590332  seconds to pickle the checkpoint
step: 0 loss: 0.0354757122695446
about to compute gradient
19.138338088989258  seconds to compute gradient
0.0029914379119873047  seconds to apply mask to gradient
0.68670654296875  seconds to compute optimizer update
0.3168156147003174  seconds to apply optimizer update
0.08335614204406738  seconds to pickle the checkpoint
step: 1 loss: 0.026163488626480103
about to compute gradient
18.732919931411743  seconds to compute gradient
0.0021791458129882812  seconds to apply mask to gradient
0.687671422958374  seconds to compute optimizer update
0.31440091133117676  seconds to apply optimizer update
0.13613057136535645  seconds to pickle the checkpoint
step: 2 loss: 0.018400786444544792
about to compute gradient
18.9794921875  seconds to compute gradient
0.0020329952239990234  seconds to apply mask to gradient
0.720984935760498  seconds to compute optimizer update
0.3170125484466553  seconds to apply optimizer update
0.0866096019744873  seconds to pickle the checkpoint
step: 3 loss: 0.012148668058216572
about to compute gradient
19.000873804092407  seconds to compute gradient
0.0020263195037841797  seconds to apply mask to gradient
0.6716735363006592  seconds to compute optimizer update
0.3175547122955322  seconds to apply optimizer update
0.08353090286254883  seconds to pickle the checkpoint
step: 4 loss: 0.007514637429267168
about to compute gradient
18.973819732666016  seconds to compute gradient
0.0019989013671875  seconds to apply mask to gradient
0.6852257251739502  seconds to compute optimizer update
0.3215157985687256  seconds to apply optimizer update
0.08600997924804688  seconds to pickle the checkpoint
step: 5 loss: 0.00431094178929925
about to compute gradient
18.957716464996338  seconds to compute gradient
0.002956390380859375  seconds to apply mask to gradient
0.6870474815368652  seconds to compute optimizer update
0.3183917999267578  seconds to apply optimizer update
0.08764147758483887  seconds to pickle the checkpoint
step: 6 loss: 0.002259601606056094
about to compute gradient
18.897271156311035  seconds to compute gradient
0.0020339488983154297  seconds to apply mask to gradient
0.6759889125823975  seconds to compute optimizer update
0.3220491409301758  seconds to apply optimizer update
0.08635354042053223  seconds to pickle the checkpoint
step: 7 loss: 0.0013064906233921647
about to compute gradient
18.786797046661377  seconds to compute gradient
0.001998424530029297  seconds to apply mask to gradient
0.7262425422668457  seconds to compute optimizer update
0.3140418529510498  seconds to apply optimizer update
0.08491826057434082  seconds to pickle the checkpoint
step: 8 loss: 0.0014113113284111023
about to compute gradient
19.132558584213257  seconds to compute gradient
0.0017061233520507812  seconds to apply mask to gradient
0.6831398010253906  seconds to compute optimizer update
0.32276439666748047  seconds to apply optimizer update
0.08869671821594238  seconds to pickle the checkpoint
step: 9 loss: 0.002200515242293477
about to compute gradient
19.07166290283203  seconds to compute gradient
0.0019173622131347656  seconds to apply mask to gradient
0.6899235248565674  seconds to compute optimizer update
0.3267083168029785  seconds to apply optimizer update
0.08817815780639648  seconds to pickle the checkpoint
step: 10 loss: 0.0030318493954837322
about to compute gradient
19.290691137313843  seconds to compute gradient
0.001992464065551758  seconds to apply mask to gradient
0.6829254627227783  seconds to compute optimizer update
0.31689929962158203  seconds to apply optimizer update
0.08811020851135254  seconds to pickle the checkpoint
step: 11 loss: 0.0034678843803703785
about to compute gradient
18.914902210235596  seconds to compute gradient
0.0019965171813964844  seconds to apply mask to gradient
0.6782755851745605  seconds to compute optimizer update
0.3159065246582031  seconds to apply optimizer update
0.13126778602600098  seconds to pickle the checkpoint
step: 12 loss: 0.003403319278731942
about to compute gradient
19.055140733718872  seconds to compute gradient
0.0038766860961914062  seconds to apply mask to gradient
0.7114243507385254  seconds to compute optimizer update
0.3185696601867676  seconds to apply optimizer update
0.08597612380981445  seconds to pickle the checkpoint
step: 13 loss: 0.002903914311900735
about to compute gradient
18.922083139419556  seconds to compute gradient
0.0015652179718017578  seconds to apply mask to gradient
0.6882534027099609  seconds to compute optimizer update
0.3136332035064697  seconds to apply optimizer update
0.08530759811401367  seconds to pickle the checkpoint
step: 14 loss: 0.0021552331745624542
about to compute gradient
18.970835208892822  seconds to compute gradient
0.0018732547760009766  seconds to apply mask to gradient
0.6673364639282227  seconds to compute optimizer update
0.31766438484191895  seconds to apply optimizer update
0.08911967277526855  seconds to pickle the checkpoint
step: 15 loss: 0.0013782086316496134
about to compute gradient
18.831491231918335  seconds to compute gradient
0.0020258426666259766  seconds to apply mask to gradient
0.6806759834289551  seconds to compute optimizer update
0.3170125484466553  seconds to apply optimizer update
0.08646345138549805  seconds to pickle the checkpoint
step: 16 loss: 0.0007399263558909297
about to compute gradient
18.86366868019104  seconds to compute gradient
0.0029981136322021484  seconds to apply mask to gradient
0.6986806392669678  seconds to compute optimizer update
0.32060813903808594  seconds to apply optimizer update
0.0866093635559082  seconds to pickle the checkpoint
step: 17 loss: 0.00032281744643114507
about to compute gradient
19.029839515686035  seconds to compute gradient
0.0019583702087402344  seconds to apply mask to gradient
0.6785955429077148  seconds to compute optimizer update
0.3148152828216553  seconds to apply optimizer update
0.0862727165222168  seconds to pickle the checkpoint
step: 18 loss: 0.00013792651589028537
about to compute gradient
18.63314700126648  seconds to compute gradient
0.0030248165130615234  seconds to apply mask to gradient
0.6728665828704834  seconds to compute optimizer update
0.31665515899658203  seconds to apply optimizer update
0.13603734970092773  seconds to pickle the checkpoint
step: 19 loss: 0.00014717079466208816
about to compute gradient
18.79073476791382  seconds to compute gradient
0.0020322799682617188  seconds to apply mask to gradient
0.7331664562225342  seconds to compute optimizer update
0.31694531440734863  seconds to apply optimizer update
0.08736157417297363  seconds to pickle the checkpoint
step: 20 loss: 0.00028657043003477156
about to compute gradient
19.021153926849365  seconds to compute gradient
0.0030236244201660156  seconds to apply mask to gradient
0.6697795391082764  seconds to compute optimizer update
0.320659875869751  seconds to apply optimizer update
0.08330988883972168  seconds to pickle the checkpoint
step: 21 loss: 0.0004809727834071964
about to compute gradient
18.855852127075195  seconds to compute gradient
0.001995563507080078  seconds to apply mask to gradient
0.673332691192627  seconds to compute optimizer update
0.3259248733520508  seconds to apply optimizer update
0.09484410285949707  seconds to pickle the checkpoint
step: 22 loss: 0.0006583115318790078
about to compute gradient
18.890756607055664  seconds to compute gradient
0.0019910335540771484  seconds to apply mask to gradient
0.6881799697875977  seconds to compute optimizer update
0.3181641101837158  seconds to apply optimizer update
0.11291933059692383  seconds to pickle the checkpoint
step: 23 loss: 0.0007675852393731475
about to compute gradient
18.880193948745728  seconds to compute gradient
0.002303600311279297  seconds to apply mask to gradient
0.6800785064697266  seconds to compute optimizer update
0.31744885444641113  seconds to apply optimizer update
0.08655405044555664  seconds to pickle the checkpoint
step: 24 loss: 0.0007867505773901939
about to compute gradient
18.876424074172974  seconds to compute gradient
0.0020284652709960938  seconds to apply mask to gradient
0.6859695911407471  seconds to compute optimizer update
0.3135404586791992  seconds to apply optimizer update
0.0845799446105957  seconds to pickle the checkpoint
step: 25 loss: 0.0007201267872005701
about to compute gradient
18.849894523620605  seconds to compute gradient
0.0021414756774902344  seconds to apply mask to gradient
0.6823790073394775  seconds to compute optimizer update
0.3203907012939453  seconds to apply optimizer update
0.08536005020141602  seconds to pickle the checkpoint
step: 26 loss: 0.0005904420977458358
about to compute gradient
18.95861291885376  seconds to compute gradient
0.0019960403442382812  seconds to apply mask to gradient
0.680206298828125  seconds to compute optimizer update
0.3152005672454834  seconds to apply optimizer update
0.08572602272033691  seconds to pickle the checkpoint
step: 27 loss: 0.00042936409590765834
about to compute gradient
18.74246644973755  seconds to compute gradient
0.002026081085205078  seconds to apply mask to gradient
0.6757938861846924  seconds to compute optimizer update
0.31642746925354004  seconds to apply optimizer update
0.0872342586517334  seconds to pickle the checkpoint
step: 28 loss: 0.0002690087421797216
about to compute gradient
18.89453363418579  seconds to compute gradient
0.002062559127807617  seconds to apply mask to gradient
0.6930806636810303  seconds to compute optimizer update
0.31618165969848633  seconds to apply optimizer update
0.08868217468261719  seconds to pickle the checkpoint
step: 29 loss: 0.00013565627159550786
>>> for n_step in range(30):
...     changing_output, opt_state, loss = step(changing_output, opt_state)
...     start_time = time.time()
...     with open('changing_output.pkl', 'wb') as f:
...         pickle.dump(changing_output, f)
...     with open('opt_state.pkl', 'wb') as f:
...         pickle.dump(opt_state, f)
...     print(time.time()-start_time, " seconds to pickle the checkpoint")
...     print(f'step: {n_step} loss: {loss}')
...
about to compute gradient
19.590819597244263  seconds to compute gradient
0.0020313262939453125  seconds to apply mask to gradient
0.6895027160644531  seconds to compute optimizer update
0.31601619720458984  seconds to apply optimizer update
0.08776259422302246  seconds to pickle the checkpoint
step: 0 loss: 4.599140083882958e-05
about to compute gradient
19.093367099761963  seconds to compute gradient
0.0019910335540771484  seconds to apply mask to gradient
0.6959700584411621  seconds to compute optimizer update
0.3138759136199951  seconds to apply optimizer update
0.08415484428405762  seconds to pickle the checkpoint
step: 1 loss: 5.737433184549445e-06
about to compute gradient
22.10770297050476  seconds to compute gradient
0.002989530563354492  seconds to apply mask to gradient
0.803682804107666  seconds to compute optimizer update
0.3824918270111084  seconds to apply optimizer update
0.17954444885253906  seconds to pickle the checkpoint
step: 2 loss: 1.0678832950361539e-05
about to compute gradient
21.10969638824463  seconds to compute gradient
0.0029637813568115234  seconds to apply mask to gradient
0.7734708786010742  seconds to compute optimizer update
0.32320117950439453  seconds to apply optimizer update
0.08905172348022461  seconds to pickle the checkpoint
step: 3 loss: 4.742630699183792e-05
about to compute gradient
19.660014629364014  seconds to compute gradient
0.0020265579223632812  seconds to apply mask to gradient
0.6992781162261963  seconds to compute optimizer update
0.3226888179779053  seconds to apply optimizer update
0.08515620231628418  seconds to pickle the checkpoint
step: 4 loss: 9.795540245249867e-05
about to compute gradient
19.825724124908447  seconds to compute gradient
0.0019826889038085938  seconds to apply mask to gradient
0.7398166656494141  seconds to compute optimizer update
0.3300158977508545  seconds to apply optimizer update
0.15489912033081055  seconds to pickle the checkpoint
step: 5 loss: 0.00014456109784077853
about to compute gradient
20.297054052352905  seconds to compute gradient
0.001996278762817383  seconds to apply mask to gradient
0.717442512512207  seconds to compute optimizer update
0.32288408279418945  seconds to apply optimizer update
0.1335582733154297  seconds to pickle the checkpoint
step: 6 loss: 0.000174226937815547
about to compute gradient
19.347107887268066  seconds to compute gradient
0.000997781753540039  seconds to apply mask to gradient
0.6966462135314941  seconds to compute optimizer update
0.33576250076293945  seconds to apply optimizer update
0.13386297225952148  seconds to pickle the checkpoint
step: 7 loss: 0.00018103205366060138
about to compute gradient
19.271125078201294  seconds to compute gradient
0.0010340213775634766  seconds to apply mask to gradient
0.7079346179962158  seconds to compute optimizer update
0.32558488845825195  seconds to apply optimizer update
0.13129782676696777  seconds to pickle the checkpoint
step: 8 loss: 0.00016600820526946336
about to compute gradient
19.39151120185852  seconds to compute gradient
0.0019953250885009766  seconds to apply mask to gradient
0.7009906768798828  seconds to compute optimizer update
0.3233494758605957  seconds to apply optimizer update
0.13123345375061035  seconds to pickle the checkpoint
step: 9 loss: 0.00013552674499806017
about to compute gradient
19.356195211410522  seconds to compute gradient
0.0020334720611572266  seconds to apply mask to gradient
0.7117917537689209  seconds to compute optimizer update
0.3230602741241455  seconds to apply optimizer update
0.13649559020996094  seconds to pickle the checkpoint
step: 10 loss: 9.819339902605861e-05
about to compute gradient
19.42587947845459  seconds to compute gradient
0.001959562301635742  seconds to apply mask to gradient
0.6898558139801025  seconds to compute optimizer update
0.3187110424041748  seconds to apply optimizer update
0.14037656784057617  seconds to pickle the checkpoint
step: 11 loss: 6.227995618246496e-05
about to compute gradient
19.260783195495605  seconds to compute gradient
0.001996278762817383  seconds to apply mask to gradient
0.6850552558898926  seconds to compute optimizer update
0.3233819007873535  seconds to apply optimizer update
0.1350083351135254  seconds to pickle the checkpoint
step: 12 loss: 3.382264185347594e-05
about to compute gradient
19.2659113407135  seconds to compute gradient
0.0019485950469970703  seconds to apply mask to gradient
0.7078604698181152  seconds to compute optimizer update
0.3199427127838135  seconds to apply optimizer update
0.1363997459411621  seconds to pickle the checkpoint
step: 13 loss: 1.5849678675294854e-05
about to compute gradient
19.20763373374939  seconds to compute gradient
0.0020020008087158203  seconds to apply mask to gradient
0.7300395965576172  seconds to compute optimizer update
0.3212006092071533  seconds to apply optimizer update
0.13521051406860352  seconds to pickle the checkpoint
step: 14 loss: 8.442830221611075e-06
about to compute gradient
19.314616441726685  seconds to compute gradient
0.0020325183868408203  seconds to apply mask to gradient
0.7141013145446777  seconds to compute optimizer update
0.3224828243255615  seconds to apply optimizer update
0.13653135299682617  seconds to pickle the checkpoint
step: 15 loss: 9.799421604839154e-06
about to compute gradient
19.416043519973755  seconds to compute gradient
0.0020287036895751953  seconds to apply mask to gradient
0.6834931373596191  seconds to compute optimizer update
0.32625651359558105  seconds to apply optimizer update
0.13423562049865723  seconds to pickle the checkpoint
step: 16 loss: 1.6973019228316844e-05
about to compute gradient
19.235044956207275  seconds to compute gradient
0.0022666454315185547  seconds to apply mask to gradient
0.6922907829284668  seconds to compute optimizer update
0.32485318183898926  seconds to apply optimizer update
0.13377928733825684  seconds to pickle the checkpoint
step: 17 loss: 2.6673031243262812e-05
about to compute gradient
19.265795946121216  seconds to compute gradient
0.0019969940185546875  seconds to apply mask to gradient
0.7050888538360596  seconds to compute optimizer update
0.3236246109008789  seconds to apply optimizer update
0.1331632137298584  seconds to pickle the checkpoint
step: 18 loss: 3.5900397051591426e-05
about to compute gradient
19.513681411743164  seconds to compute gradient
0.0020999908447265625  seconds to apply mask to gradient
0.7125518321990967  seconds to compute optimizer update
0.32868242263793945  seconds to apply optimizer update
0.13070368766784668  seconds to pickle the checkpoint
step: 19 loss: 4.2361840314697474e-05
about to compute gradient
19.338971614837646  seconds to compute gradient
0.001001119613647461  seconds to apply mask to gradient
0.6936960220336914  seconds to compute optimizer update
0.31568288803100586  seconds to apply optimizer update
0.13241124153137207  seconds to pickle the checkpoint
step: 20 loss: 4.469383566174656e-05
about to compute gradient
19.280699491500854  seconds to compute gradient
0.001995086669921875  seconds to apply mask to gradient
0.7079160213470459  seconds to compute optimizer update
0.3268253803253174  seconds to apply optimizer update
0.1373295783996582  seconds to pickle the checkpoint
step: 21 loss: 4.253018050803803e-05
about to compute gradient
19.396090507507324  seconds to compute gradient
0.0029876232147216797  seconds to apply mask to gradient
0.6954927444458008  seconds to compute optimizer update
0.3223860263824463  seconds to apply optimizer update
0.13547062873840332  seconds to pickle the checkpoint
step: 22 loss: 3.6439450923353434e-05
about to compute gradient
19.126989126205444  seconds to compute gradient
0.002998828887939453  seconds to apply mask to gradient
0.6840593814849854  seconds to compute optimizer update
0.32758450508117676  seconds to apply optimizer update
0.1378026008605957  seconds to pickle the checkpoint
step: 23 loss: 2.7736819902202114e-05
about to compute gradient
19.32681918144226  seconds to compute gradient
0.0010352134704589844  seconds to apply mask to gradient
0.709930419921875  seconds to compute optimizer update
0.31862354278564453  seconds to apply optimizer update
0.13120102882385254  seconds to pickle the checkpoint
step: 24 loss: 1.818732744141016e-05
about to compute gradient
19.236315965652466  seconds to compute gradient
0.0019860267639160156  seconds to apply mask to gradient
0.7058634757995605  seconds to compute optimizer update
0.323822021484375  seconds to apply optimizer update
0.13853669166564941  seconds to pickle the checkpoint
step: 25 loss: 9.624853191780858e-06
about to compute gradient
19.13528323173523  seconds to compute gradient
0.0019872188568115234  seconds to apply mask to gradient
0.6928369998931885  seconds to compute optimizer update
0.3253350257873535  seconds to apply optimizer update
0.1326615810394287  seconds to pickle the checkpoint
step: 26 loss: 3.549018174453522e-06
about to compute gradient
19.36052656173706  seconds to compute gradient
0.001994609832763672  seconds to apply mask to gradient
0.7057015895843506  seconds to compute optimizer update
0.3151741027832031  seconds to apply optimizer update
0.12975072860717773  seconds to pickle the checkpoint
step: 27 loss: 8.003764833119931e-07
about to compute gradient
19.160517930984497  seconds to compute gradient
0.001998424530029297  seconds to apply mask to gradient
0.6800088882446289  seconds to compute optimizer update
0.32692575454711914  seconds to apply optimizer update
0.13410091400146484  seconds to pickle the checkpoint
step: 28 loss: 1.2989762581128161e-06
about to compute gradient
19.114811897277832  seconds to compute gradient
0.0020270347595214844  seconds to apply mask to gradient
0.6990368366241455  seconds to compute optimizer update
0.32794690132141113  seconds to apply optimizer update
0.13082551956176758  seconds to pickle the checkpoint
step: 29 loss: 4.18999070461723e-06
>>>
```

Learning rate 0.01, 11 iterations of the network, here are 60 steps, good convergence:

```
size (leaves): 2944 2906 37 1
0.7846894264221191  seconds
initial loss  0.35485545  computed in  3.2467081546783447  seconds
about to compute gradient
140.0121364593506  seconds to compute gradient
0.0033533573150634766  seconds to apply mask to gradient
17.438814163208008  seconds to compute optimizer update
0.327923059463501  seconds to apply optimizer update
0.08514118194580078  seconds to pickle the checkpoint
step: 0 loss: 0.3548554480075836
about to compute gradient
136.91361331939697  seconds to compute gradient
0.003228902816772461  seconds to apply mask to gradient
0.689399242401123  seconds to compute optimizer update
0.3250467777252197  seconds to apply optimizer update
0.0924837589263916  seconds to pickle the checkpoint
step: 1 loss: 0.26069340109825134
about to compute gradient
137.12459230422974  seconds to compute gradient
0.0020287036895751953  seconds to apply mask to gradient
0.6717770099639893  seconds to compute optimizer update
0.32274460792541504  seconds to apply optimizer update
0.08788824081420898  seconds to pickle the checkpoint
step: 2 loss: 0.1823614537715912
about to compute gradient
137.25679564476013  seconds to compute gradient
0.003953695297241211  seconds to apply mask to gradient
0.7314612865447998  seconds to compute optimizer update
0.33530211448669434  seconds to apply optimizer update
0.08977532386779785  seconds to pickle the checkpoint
step: 3 loss: 0.11964986473321915
about to compute gradient
138.7148506641388  seconds to compute gradient
0.0039882659912109375  seconds to apply mask to gradient
0.6850051879882812  seconds to compute optimizer update
0.3141798973083496  seconds to apply optimizer update
0.09204387664794922  seconds to pickle the checkpoint
step: 4 loss: 0.07365388423204422
about to compute gradient
136.84787464141846  seconds to compute gradient
0.002954244613647461  seconds to apply mask to gradient
0.672304630279541  seconds to compute optimizer update
0.3157665729522705  seconds to apply optimizer update
0.09474396705627441  seconds to pickle the checkpoint
step: 5 loss: 0.04192956164479256
about to compute gradient
136.75928592681885  seconds to compute gradient
0.0046575069427490234  seconds to apply mask to gradient
0.6780800819396973  seconds to compute optimizer update
0.3159940242767334  seconds to apply optimizer update
0.08604192733764648  seconds to pickle the checkpoint
step: 6 loss: 0.021799681708216667
about to compute gradient
136.6084430217743  seconds to compute gradient
0.0020294189453125  seconds to apply mask to gradient
0.6759183406829834  seconds to compute optimizer update
0.3168158531188965  seconds to apply optimizer update
0.08905982971191406  seconds to pickle the checkpoint
step: 7 loss: 0.013289304450154305
about to compute gradient
149.46420979499817  seconds to compute gradient
0.007977008819580078  seconds to apply mask to gradient
0.6795110702514648  seconds to compute optimizer update
0.3252527713775635  seconds to apply optimizer update
0.08718514442443848  seconds to pickle the checkpoint
step: 8 loss: 0.01590878516435623
about to compute gradient
143.18981742858887  seconds to compute gradient
0.002985715866088867  seconds to apply mask to gradient
0.6972615718841553  seconds to compute optimizer update
0.3223612308502197  seconds to apply optimizer update
0.08521413803100586  seconds to pickle the checkpoint
step: 9 loss: 0.02453148551285267
about to compute gradient
136.84611415863037  seconds to compute gradient
0.0029592514038085938  seconds to apply mask to gradient
0.6739885807037354  seconds to compute optimizer update
0.3321652412414551  seconds to apply optimizer update
0.09074974060058594  seconds to pickle the checkpoint
step: 10 loss: 0.03199070692062378
about to compute gradient
136.07473754882812  seconds to compute gradient
0.0030303001403808594  seconds to apply mask to gradient
0.694751501083374  seconds to compute optimizer update
0.32501792907714844  seconds to apply optimizer update
0.0864722728729248  seconds to pickle the checkpoint
step: 11 loss: 0.034649137407541275
about to compute gradient
136.75226068496704  seconds to compute gradient
0.0028514862060546875  seconds to apply mask to gradient
0.691866397857666  seconds to compute optimizer update
0.3184089660644531  seconds to apply optimizer update
0.0874168872833252  seconds to pickle the checkpoint
step: 12 loss: 0.032269738614559174
about to compute gradient
140.03930234909058  seconds to compute gradient
0.0020284652709960938  seconds to apply mask to gradient
0.6855969429016113  seconds to compute optimizer update
0.32041072845458984  seconds to apply optimizer update
0.08849334716796875  seconds to pickle the checkpoint
step: 13 loss: 0.0262303464114666
about to compute gradient
139.9166944026947  seconds to compute gradient
0.0036339759826660156  seconds to apply mask to gradient
0.6888582706451416  seconds to compute optimizer update
0.3145134449005127  seconds to apply optimizer update
0.08498930931091309  seconds to pickle the checkpoint
step: 14 loss: 0.01868034154176712
about to compute gradient
139.0188295841217  seconds to compute gradient
0.0049877166748046875  seconds to apply mask to gradient
0.6963529586791992  seconds to compute optimizer update
0.31882238388061523  seconds to apply optimizer update
0.0838632583618164  seconds to pickle the checkpoint
step: 15 loss: 0.011591707356274128
about to compute gradient
140.90592169761658  seconds to compute gradient
0.0029954910278320312  seconds to apply mask to gradient
0.6756763458251953  seconds to compute optimizer update
0.32648634910583496  seconds to apply optimizer update
0.08617901802062988  seconds to pickle the checkpoint
step: 16 loss: 0.00621174369007349
about to compute gradient
136.2317671775818  seconds to compute gradient
0.004990577697753906  seconds to apply mask to gradient
0.6781694889068604  seconds to compute optimizer update
0.32879638671875  seconds to apply optimizer update
0.08332490921020508  seconds to pickle the checkpoint
step: 17 loss: 0.0029754245188087225
about to compute gradient
137.24138140678406  seconds to compute gradient
0.002992391586303711  seconds to apply mask to gradient
0.6811079978942871  seconds to compute optimizer update
0.3258240222930908  seconds to apply optimizer update
0.0872044563293457  seconds to pickle the checkpoint
step: 18 loss: 0.0017396982293576002
about to compute gradient
140.5836145877838  seconds to compute gradient
0.0030319690704345703  seconds to apply mask to gradient
0.6994278430938721  seconds to compute optimizer update
0.3284115791320801  seconds to apply optimizer update
0.0844576358795166  seconds to pickle the checkpoint
step: 19 loss: 0.0020411242730915546
about to compute gradient
140.4854805469513  seconds to compute gradient
0.004996299743652344  seconds to apply mask to gradient
0.676738977432251  seconds to compute optimizer update
0.32702088356018066  seconds to apply optimizer update
0.08508467674255371  seconds to pickle the checkpoint
step: 20 loss: 0.003292851848527789
about to compute gradient
140.01698875427246  seconds to compute gradient
0.0025322437286376953  seconds to apply mask to gradient
0.697800874710083  seconds to compute optimizer update
0.3239412307739258  seconds to apply optimizer update
0.09467172622680664  seconds to pickle the checkpoint
step: 21 loss: 0.00490614166483283
about to compute gradient
139.50380873680115  seconds to compute gradient
0.003914594650268555  seconds to apply mask to gradient
0.673612117767334  seconds to compute optimizer update
0.3233175277709961  seconds to apply optimizer update
0.0888817310333252  seconds to pickle the checkpoint
step: 22 loss: 0.006353046279400587
about to compute gradient
139.53036737442017  seconds to compute gradient
0.0030362606048583984  seconds to apply mask to gradient
0.6830441951751709  seconds to compute optimizer update
0.3295011520385742  seconds to apply optimizer update
0.08658099174499512  seconds to pickle the checkpoint
step: 23 loss: 0.007234731689095497
about to compute gradient
139.25284481048584  seconds to compute gradient
0.004235744476318359  seconds to apply mask to gradient
0.6801135540008545  seconds to compute optimizer update
0.31784963607788086  seconds to apply optimizer update
0.09323263168334961  seconds to pickle the checkpoint
step: 24 loss: 0.0073515186086297035
about to compute gradient
139.5631618499756  seconds to compute gradient
0.0038444995880126953  seconds to apply mask to gradient
0.7042186260223389  seconds to compute optimizer update
0.32425808906555176  seconds to apply optimizer update
0.0876913070678711  seconds to pickle the checkpoint
step: 25 loss: 0.006713222712278366
about to compute gradient
140.35417819023132  seconds to compute gradient
0.0032830238342285156  seconds to apply mask to gradient
0.7001376152038574  seconds to compute optimizer update
0.3344573974609375  seconds to apply optimizer update
0.09076499938964844  seconds to pickle the checkpoint
step: 26 loss: 0.005491417832672596
about to compute gradient
139.85659456253052  seconds to compute gradient
0.0029990673065185547  seconds to apply mask to gradient
0.6721065044403076  seconds to compute optimizer update
0.32399415969848633  seconds to apply optimizer update
0.09278082847595215  seconds to pickle the checkpoint
step: 27 loss: 0.00394437275826931
about to compute gradient
139.6845097541809  seconds to compute gradient
0.003989696502685547  seconds to apply mask to gradient
0.6961748600006104  seconds to compute optimizer update
0.32810044288635254  seconds to apply optimizer update
0.09044075012207031  seconds to pickle the checkpoint
step: 28 loss: 0.002411929424852133
about to compute gradient
139.184476852417  seconds to compute gradient
0.004021167755126953  seconds to apply mask to gradient
0.689633846282959  seconds to compute optimizer update
0.31514835357666016  seconds to apply optimizer update
0.0842905044555664  seconds to pickle the checkpoint
step: 29 loss: 0.0011566116008907557
>>> for n_step in range(30):
...     changing_output, opt_state, loss = step(changing_output, opt_state)
...     start_time = time.time()
...     with open('changing_output.pkl', 'wb') as f:
...         pickle.dump(changing_output, f)
...     with open('opt_state.pkl', 'wb') as f:
...         pickle.dump(opt_state, f)
...     print(time.time()-start_time, " seconds to pickle the checkpoint")
...     print(f'step: {n_step} loss: {loss}')
...
about to compute gradient
151.5742211341858  seconds to compute gradient
0.0020143985748291016  seconds to apply mask to gradient
0.7273039817810059  seconds to compute optimizer update
0.3225133419036865  seconds to apply optimizer update
0.0878458023071289  seconds to pickle the checkpoint
step: 0 loss: 0.00035293883411213756
about to compute gradient
149.10719442367554  seconds to compute gradient
0.003580331802368164  seconds to apply mask to gradient
0.6925818920135498  seconds to compute optimizer update
0.31981348991394043  seconds to apply optimizer update
0.08684492111206055  seconds to pickle the checkpoint
step: 1 loss: 5.671753024216741e-05
about to compute gradient
141.0310971736908  seconds to compute gradient
0.003989458084106445  seconds to apply mask to gradient
0.694143533706665  seconds to compute optimizer update
0.32477641105651855  seconds to apply optimizer update
0.08970475196838379  seconds to pickle the checkpoint
step: 2 loss: 0.00020644348114728928
about to compute gradient
143.5982882976532  seconds to compute gradient
0.003993034362792969  seconds to apply mask to gradient
0.7059285640716553  seconds to compute optimizer update
0.3237934112548828  seconds to apply optimizer update
0.09405875205993652  seconds to pickle the checkpoint
step: 3 loss: 0.0006452361703850329
about to compute gradient
143.34210062026978  seconds to compute gradient
0.004988670349121094  seconds to apply mask to gradient
0.7027115821838379  seconds to compute optimizer update
0.32598209381103516  seconds to apply optimizer update
0.08646798133850098  seconds to pickle the checkpoint
step: 4 loss: 0.0011670937528833747
about to compute gradient
140.07610750198364  seconds to compute gradient
0.0038971900939941406  seconds to apply mask to gradient
0.699343204498291  seconds to compute optimizer update
0.3198864459991455  seconds to apply optimizer update
0.13736510276794434  seconds to pickle the checkpoint
step: 5 loss: 0.0015831845812499523
about to compute gradient
141.152734041214  seconds to compute gradient
0.003998994827270508  seconds to apply mask to gradient
0.7059276103973389  seconds to compute optimizer update
0.3322947025299072  seconds to apply optimizer update
0.08750605583190918  seconds to pickle the checkpoint
step: 6 loss: 0.0017765021184459329
about to compute gradient
141.57313704490662  seconds to compute gradient
0.003993511199951172  seconds to apply mask to gradient
0.6836872100830078  seconds to compute optimizer update
0.35016322135925293  seconds to apply optimizer update
0.08599114418029785  seconds to pickle the checkpoint
step: 7 loss: 0.0017214466352015734
about to compute gradient
139.93161368370056  seconds to compute gradient
0.00199127197265625  seconds to apply mask to gradient
0.6804649829864502  seconds to compute optimizer update
0.31966495513916016  seconds to apply optimizer update
0.09054708480834961  seconds to pickle the checkpoint
step: 8 loss: 0.0014673761324957013
about to compute gradient
141.23307061195374  seconds to compute gradient
0.002992391586303711  seconds to apply mask to gradient
0.6938989162445068  seconds to compute optimizer update
0.3197035789489746  seconds to apply optimizer update
0.08850646018981934  seconds to pickle the checkpoint
step: 9 loss: 0.0011061893310397863
about to compute gradient
139.6872537136078  seconds to compute gradient
0.003991365432739258  seconds to apply mask to gradient
0.6826348304748535  seconds to compute optimizer update
0.32497501373291016  seconds to apply optimizer update
0.13286781311035156  seconds to pickle the checkpoint
step: 10 loss: 0.0007332832901738584
about to compute gradient
141.11041069030762  seconds to compute gradient
0.002995014190673828  seconds to apply mask to gradient
0.7052702903747559  seconds to compute optimizer update
0.3221862316131592  seconds to apply optimizer update
0.0888206958770752  seconds to pickle the checkpoint
step: 11 loss: 0.0004224172153044492
about to compute gradient
140.144428730011  seconds to compute gradient
0.003977298736572266  seconds to apply mask to gradient
0.6859328746795654  seconds to compute optimizer update
0.3277909755706787  seconds to apply optimizer update
0.08634376525878906  seconds to pickle the checkpoint
step: 12 loss: 0.00021376932272687554
about to compute gradient
140.32114243507385  seconds to compute gradient
0.003988742828369141  seconds to apply mask to gradient
0.6983299255371094  seconds to compute optimizer update
0.32895326614379883  seconds to apply optimizer update
0.08719730377197266  seconds to pickle the checkpoint
step: 13 loss: 0.00011489843745948747
about to compute gradient
140.32929968833923  seconds to compute gradient
0.002076864242553711  seconds to apply mask to gradient
0.7036788463592529  seconds to compute optimizer update
0.32596254348754883  seconds to apply optimizer update
0.0939645767211914  seconds to pickle the checkpoint
step: 14 loss: 0.00010927221592282876
about to compute gradient
141.14444613456726  seconds to compute gradient
0.0040264129638671875  seconds to apply mask to gradient
0.6931767463684082  seconds to compute optimizer update
0.32014894485473633  seconds to apply optimizer update
0.0871129035949707  seconds to pickle the checkpoint
step: 15 loss: 0.0001671394711593166
about to compute gradient
140.69698309898376  seconds to compute gradient
0.002983570098876953  seconds to apply mask to gradient
0.711597204208374  seconds to compute optimizer update
0.3220059871673584  seconds to apply optimizer update
0.09022760391235352  seconds to pickle the checkpoint
step: 16 loss: 0.0002551053185015917
about to compute gradient
140.03005957603455  seconds to compute gradient
0.0047152042388916016  seconds to apply mask to gradient
0.6975507736206055  seconds to compute optimizer update
0.3266580104827881  seconds to apply optimizer update
0.08811354637145996  seconds to pickle the checkpoint
step: 17 loss: 0.00034281882108189166
about to compute gradient
139.65303945541382  seconds to compute gradient
0.0029206275939941406  seconds to apply mask to gradient
0.696819543838501  seconds to compute optimizer update
0.3203272819519043  seconds to apply optimizer update
0.0921030044555664  seconds to pickle the checkpoint
step: 18 loss: 0.00040682998951524496
about to compute gradient
139.60197973251343  seconds to compute gradient
0.003986358642578125  seconds to apply mask to gradient
0.7125511169433594  seconds to compute optimizer update
0.3233342170715332  seconds to apply optimizer update
0.08768343925476074  seconds to pickle the checkpoint
step: 19 loss: 0.000432492233812809
about to compute gradient
140.57135558128357  seconds to compute gradient
0.0020325183868408203  seconds to apply mask to gradient
0.7010979652404785  seconds to compute optimizer update
0.3184351921081543  seconds to apply optimizer update
0.09036588668823242  seconds to pickle the checkpoint
step: 20 loss: 0.00041476174374110997
about to compute gradient
140.71945238113403  seconds to compute gradient
0.0029916763305664062  seconds to apply mask to gradient
0.7045414447784424  seconds to compute optimizer update
0.32245516777038574  seconds to apply optimizer update
0.0867922306060791  seconds to pickle the checkpoint
step: 21 loss: 0.00035807848325930536
about to compute gradient
139.85712909698486  seconds to compute gradient
0.0030257701873779297  seconds to apply mask to gradient
0.6937589645385742  seconds to compute optimizer update
0.32306432723999023  seconds to apply optimizer update
0.14151883125305176  seconds to pickle the checkpoint
step: 22 loss: 0.0002748639089986682
about to compute gradient
139.44893527030945  seconds to compute gradient
0.003950357437133789  seconds to apply mask to gradient
0.6864244937896729  seconds to compute optimizer update
0.3268930912017822  seconds to apply optimizer update
0.08799147605895996  seconds to pickle the checkpoint
step: 23 loss: 0.00018252068548463285
about to compute gradient
139.76305770874023  seconds to compute gradient
0.0029964447021484375  seconds to apply mask to gradient
0.6738152503967285  seconds to compute optimizer update
0.3196291923522949  seconds to apply optimizer update
0.0867149829864502  seconds to pickle the checkpoint
step: 24 loss: 9.948737715603784e-05
about to compute gradient
139.5781285762787  seconds to compute gradient
0.0029914379119873047  seconds to apply mask to gradient
0.6874041557312012  seconds to compute optimizer update
0.3294851779937744  seconds to apply optimizer update
0.08822083473205566  seconds to pickle the checkpoint
step: 25 loss: 4.0926657675299793e-05
about to compute gradient
141.0137917995453  seconds to compute gradient
0.0029916763305664062  seconds to apply mask to gradient
0.6771509647369385  seconds to compute optimizer update
0.32923316955566406  seconds to apply optimizer update
0.09134101867675781  seconds to pickle the checkpoint
step: 26 loss: 1.5113464542082511e-05
about to compute gradient
139.59402465820312  seconds to compute gradient
0.004027128219604492  seconds to apply mask to gradient
0.688103199005127  seconds to compute optimizer update
0.33127498626708984  seconds to apply optimizer update
0.13434791564941406  seconds to pickle the checkpoint
step: 27 loss: 2.156305890821386e-05
about to compute gradient
141.03327250480652  seconds to compute gradient
0.003034830093383789  seconds to apply mask to gradient
0.6814570426940918  seconds to compute optimizer update
0.3285024166107178  seconds to apply optimizer update
0.08846187591552734  seconds to pickle the checkpoint
step: 28 loss: 5.1508417527657e-05
about to compute gradient
139.88825249671936  seconds to compute gradient
0.0036106109619140625  seconds to apply mask to gradient
0.6905555725097656  seconds to compute optimizer update
0.32129645347595215  seconds to apply optimizer update
0.0867624282836914  seconds to pickle the checkpoint
step: 29 loss: 9.07790454220958e-05
>>>
```

Learning rate 0.01, 140 iterations of the network (full network), initial exploration:

```
size (leaves): 2944 2906 37 1
0.8068363666534424  seconds
initial loss  412.64908  computed in  50.568336486816406  seconds
about to compute gradient
2458.0455281734467  seconds to compute gradient
0.012615442276000977  seconds to apply mask to gradient
19.157177925109863  seconds to compute optimizer update
0.3509938716888428  seconds to apply optimizer update
0.10052108764648438  seconds to pickle the checkpoint
step: 0 loss: 412.6490783691406
about to compute gradient
2202.7528104782104  seconds to compute gradient
0.005979776382446289  seconds to apply mask to gradient
0.696101188659668  seconds to compute optimizer update
0.3167421817779541  seconds to apply optimizer update
0.09392118453979492  seconds to pickle the checkpoint
step: 1 loss: 404.0504150390625
about to compute gradient
2131.663428068161  seconds to compute gradient
0.0040166378021240234  seconds to apply mask to gradient
0.6802563667297363  seconds to compute optimizer update
0.3097879886627197  seconds to apply optimizer update
0.10587072372436523  seconds to pickle the checkpoint
step: 2 loss: 395.63397216796875
about to compute gradient
2109.87535572052  seconds to compute gradient
0.003988981246948242  seconds to apply mask to gradient
0.6757621765136719  seconds to compute optimizer update
0.3166787624359131  seconds to apply optimizer update
0.1017765998840332  seconds to pickle the checkpoint
step: 3 loss: 387.1342468261719
about to compute gradient
2141.727791070938  seconds to compute gradient
0.003996849060058594  seconds to apply mask to gradient
0.6786997318267822  seconds to compute optimizer update
0.31281375885009766  seconds to apply optimizer update
0.09809160232543945  seconds to pickle the checkpoint
step: 4 loss: 378.31756591796875
about to compute gradient
2123.5096089839935  seconds to compute gradient
0.003988981246948242  seconds to apply mask to gradient
0.6770598888397217  seconds to compute optimizer update
0.31865692138671875  seconds to apply optimizer update
0.08598709106445312  seconds to pickle the checkpoint
step: 5 loss: 368.9949951171875
about to compute gradient
2117.3651399612427  seconds to compute gradient
0.0039517879486083984  seconds to apply mask to gradient
0.6655032634735107  seconds to compute optimizer update
0.31551313400268555  seconds to apply optimizer update
0.0879817008972168  seconds to pickle the checkpoint
step: 6 loss: 359.0767822265625
about to compute gradient
2138.2081577777863  seconds to compute gradient
0.004949808120727539  seconds to apply mask to gradient
0.7370359897613525  seconds to compute optimizer update
0.33890485763549805  seconds to apply optimizer update
0.11762523651123047  seconds to pickle the checkpoint
step: 7 loss: 348.41485595703125
about to compute gradient
2155.0603585243225  seconds to compute gradient
0.005976676940917969  seconds to apply mask to gradient
0.6682953834533691  seconds to compute optimizer update
0.3052690029144287  seconds to apply optimizer update
0.0894627571105957  seconds to pickle the checkpoint
step: 8 loss: 336.9759216308594
about to compute gradient
2122.1045064926147  seconds to compute gradient
0.004985809326171875  seconds to apply mask to gradient
0.6651055812835693  seconds to compute optimizer update
0.3116445541381836  seconds to apply optimizer update
0.0988759994506836  seconds to pickle the checkpoint
step: 9 loss: 324.7709045410156
about to compute gradient
2146.014261484146  seconds to compute gradient
0.005948543548583984  seconds to apply mask to gradient
0.6751830577850342  seconds to compute optimizer update
0.3123352527618408  seconds to apply optimizer update
0.10104155540466309  seconds to pickle the checkpoint
step: 10 loss: 311.823486328125
about to compute gradient
2144.4689450263977  seconds to compute gradient
0.004020214080810547  seconds to apply mask to gradient
0.6823511123657227  seconds to compute optimizer update
0.3152730464935303  seconds to apply optimizer update
0.10000944137573242  seconds to pickle the checkpoint
step: 11 loss: 298.1114501953125
about to compute gradient
2131.3866295814514  seconds to compute gradient
0.004982948303222656  seconds to apply mask to gradient
0.672675609588623  seconds to compute optimizer update
0.313122034072876  seconds to apply optimizer update
0.0906381607055664  seconds to pickle the checkpoint
step: 12 loss: 283.5918884277344
about to compute gradient
2170.137492418289  seconds to compute gradient
0.0044858455657958984  seconds to apply mask to gradient
0.6769835948944092  seconds to compute optimizer update
0.30795717239379883  seconds to apply optimizer update
0.10055732727050781  seconds to pickle the checkpoint
step: 13 loss: 268.3177795410156
about to compute gradient
2297.22211766243  seconds to compute gradient
0.00402069091796875  seconds to apply mask to gradient
0.6965768337249756  seconds to compute optimizer update
0.3196117877960205  seconds to apply optimizer update
0.09432649612426758  seconds to pickle the checkpoint
step: 14 loss: 252.50393676757812
about to compute gradient
2325.6233236789703  seconds to compute gradient
0.003988981246948242  seconds to apply mask to gradient
0.7452969551086426  seconds to compute optimizer update
0.3431355953216553  seconds to apply optimizer update
0.12319159507751465  seconds to pickle the checkpoint
step: 15 loss: 236.57833862304688
about to compute gradient
2463.720633983612  seconds to compute gradient
0.007490396499633789  seconds to apply mask to gradient
0.785071849822998  seconds to compute optimizer update
0.3459794521331787  seconds to apply optimizer update
0.11038684844970703  seconds to pickle the checkpoint
step: 16 loss: 221.24066162109375
about to compute gradient
2249.7531418800354  seconds to compute gradient
0.006490230560302734  seconds to apply mask to gradient
0.6989834308624268  seconds to compute optimizer update
0.3561055660247803  seconds to apply optimizer update
0.10642576217651367  seconds to pickle the checkpoint
step: 17 loss: 207.54212951660156
about to compute gradient
2487.287912130356  seconds to compute gradient
0.010006189346313477  seconds to apply mask to gradient
0.7910268306732178  seconds to compute optimizer update
0.395984411239624  seconds to apply optimizer update
0.11287355422973633  seconds to pickle the checkpoint
step: 18 loss: 196.9501953125
about to compute gradient
2429.420003414154  seconds to compute gradient
0.005984306335449219  seconds to apply mask to gradient
0.7561397552490234  seconds to compute optimizer update
0.33255600929260254  seconds to apply optimizer update
0.1031949520111084  seconds to pickle the checkpoint
step: 19 loss: 191.26197814941406
about to compute gradient
2575.3150787353516  seconds to compute gradient
0.008975744247436523  seconds to apply mask to gradient
0.9426419734954834  seconds to compute optimizer update
0.389554500579834  seconds to apply optimizer update
0.19142770767211914  seconds to pickle the checkpoint
step: 20 loss: 191.93817138671875
about to compute gradient
2354.4146604537964  seconds to compute gradient
0.0039904117584228516  seconds to apply mask to gradient
0.7035534381866455  seconds to compute optimizer update
0.3179309368133545  seconds to apply optimizer update
0.09240293502807617  seconds to pickle the checkpoint
step: 21 loss: 198.18374633789062
about to compute gradient
2201.387006998062  seconds to compute gradient
0.005014181137084961  seconds to apply mask to gradient
0.6746103763580322  seconds to compute optimizer update
0.3151528835296631  seconds to apply optimizer update
0.09439325332641602  seconds to pickle the checkpoint
step: 22 loss: 205.681396484375
about to compute gradient
2289.5021555423737  seconds to compute gradient
0.007313251495361328  seconds to apply mask to gradient
0.7037074565887451  seconds to compute optimizer update
0.31870293617248535  seconds to apply optimizer update
0.10957193374633789  seconds to pickle the checkpoint
step: 23 loss: 210.01959228515625
about to compute gradient
2367.0836362838745  seconds to compute gradient
0.004522085189819336  seconds to apply mask to gradient
0.7286899089813232  seconds to compute optimizer update
0.3241596221923828  seconds to apply optimizer update
0.10151028633117676  seconds to pickle the checkpoint
step: 24 loss: 209.8426513671875
about to compute gradient
2429.7458262443542  seconds to compute gradient
0.0069122314453125  seconds to apply mask to gradient
0.7810227870941162  seconds to compute optimizer update
0.34600162506103516  seconds to apply optimizer update
0.13318824768066406  seconds to pickle the checkpoint
step: 25 loss: 206.3524627685547
about to compute gradient
2420.629366159439  seconds to compute gradient
0.006991863250732422  seconds to apply mask to gradient
0.7087056636810303  seconds to compute optimizer update
0.31377720832824707  seconds to apply optimizer update
0.10711097717285156  seconds to pickle the checkpoint
step: 26 loss: 201.1053009033203
about to compute gradient
2172.4596848487854  seconds to compute gradient
0.0049860477447509766  seconds to apply mask to gradient
0.6928491592407227  seconds to compute optimizer update
0.3220062255859375  seconds to apply optimizer update
0.09282541275024414  seconds to pickle the checkpoint
step: 27 loss: 196.09564208984375
about to compute gradient
2181.1619913578033  seconds to compute gradient
0.005376338958740234  seconds to apply mask to gradient
0.6782784461975098  seconds to compute optimizer update
0.31480884552001953  seconds to apply optimizer update
0.09231019020080566  seconds to pickle the checkpoint
step: 28 loss: 192.411865234375
about to compute gradient
2184.8079063892365  seconds to compute gradient
0.004017353057861328  seconds to apply mask to gradient
0.6882259845733643  seconds to compute optimizer update
0.3100707530975342  seconds to apply optimizer update
0.10490798950195312  seconds to pickle the checkpoint
step: 29 loss: 190.34751892089844
>>> for n_step in range(30):
...     changing_output, opt_state, loss = step(changing_output, opt_state)
...     start_time = time.time()
...     with open('changing_output.pkl', 'wb') as f:
...         pickle.dump(changing_output, f)
...     with open('opt_state.pkl', 'wb') as f:
...         pickle.dump(opt_state, f)
...     print(time.time()-start_time, " seconds to pickle the checkpoint")
...     print(f'step: {n_step} loss: {loss}')
...
about to compute gradient
2177.796010017395  seconds to compute gradient
0.005075931549072266  seconds to apply mask to gradient
0.678217887878418  seconds to compute optimizer update
0.31301093101501465  seconds to apply optimizer update
0.0910484790802002  seconds to pickle the checkpoint
step: 0 loss: 189.68411254882812
about to compute gradient
2170.0337920188904  seconds to compute gradient
0.008182525634765625  seconds to apply mask to gradient
0.6819124221801758  seconds to compute optimizer update
0.3108365535736084  seconds to apply optimizer update
0.10336160659790039  seconds to pickle the checkpoint
step: 1 loss: 189.99539184570312
about to compute gradient
2163.453339576721  seconds to compute gradient
0.005422353744506836  seconds to apply mask to gradient
0.660703182220459  seconds to compute optimizer update
0.3092501163482666  seconds to apply optimizer update
0.0998680591583252  seconds to pickle the checkpoint
step: 2 loss: 190.82220458984375
about to compute gradient
2184.493145942688  seconds to compute gradient
0.004948854446411133  seconds to apply mask to gradient
0.6822905540466309  seconds to compute optimizer update
0.3193848133087158  seconds to apply optimizer update
0.09250283241271973  seconds to pickle the checkpoint
step: 3 loss: 191.7930908203125
about to compute gradient
2214.0191168785095  seconds to compute gradient
0.004987239837646484  seconds to apply mask to gradient
0.6986727714538574  seconds to compute optimizer update
0.32569313049316406  seconds to apply optimizer update
0.09272980690002441  seconds to pickle the checkpoint
step: 4 loss: 192.63839721679688
about to compute gradient
2463.4133791923523  seconds to compute gradient
0.004986286163330078  seconds to apply mask to gradient
0.8088414669036865  seconds to compute optimizer update
0.35497331619262695  seconds to apply optimizer update
0.11760592460632324  seconds to pickle the checkpoint
step: 5 loss: 193.21652221679688
about to compute gradient
2239.6150612831116  seconds to compute gradient
0.0039479732513427734  seconds to apply mask to gradient
0.6837029457092285  seconds to compute optimizer update
0.3268318176269531  seconds to apply optimizer update
0.08940720558166504  seconds to pickle the checkpoint
step: 6 loss: 193.46231079101562
about to compute gradient
2198.7869160175323  seconds to compute gradient
0.004954099655151367  seconds to apply mask to gradient
0.6792869567871094  seconds to compute optimizer update
0.3214879035949707  seconds to apply optimizer update
0.1148824691772461  seconds to pickle the checkpoint
step: 7 loss: 193.37417602539062
about to compute gradient
2264.0391252040863  seconds to compute gradient
0.0051195621490478516  seconds to apply mask to gradient
0.6811292171478271  seconds to compute optimizer update
0.3137550354003906  seconds to apply optimizer update
0.10854434967041016  seconds to pickle the checkpoint
step: 8 loss: 192.99452209472656
about to compute gradient
2187.409650325775  seconds to compute gradient
0.005133390426635742  seconds to apply mask to gradient
0.6767656803131104  seconds to compute optimizer update
0.3101224899291992  seconds to apply optimizer update
0.09097599983215332  seconds to pickle the checkpoint
step: 9 loss: 192.3944091796875
about to compute gradient
2198.742211818695  seconds to compute gradient
0.004022121429443359  seconds to apply mask to gradient
0.6704435348510742  seconds to compute optimizer update
0.31938648223876953  seconds to apply optimizer update
0.09340381622314453  seconds to pickle the checkpoint
step: 10 loss: 191.66334533691406
about to compute gradient
2200.1133618354797  seconds to compute gradient
0.006025791168212891  seconds to apply mask to gradient
0.7007510662078857  seconds to compute optimizer update
0.31638216972351074  seconds to apply optimizer update
0.11505818367004395  seconds to pickle the checkpoint
step: 11 loss: 190.89724731445312
about to compute gradient
2203.471386909485  seconds to compute gradient
0.0040547847747802734  seconds to apply mask to gradient
0.6642007827758789  seconds to compute optimizer update
0.3181631565093994  seconds to apply optimizer update
0.09096479415893555  seconds to pickle the checkpoint
step: 12 loss: 190.18783569335938
about to compute gradient
2188.0064301490784  seconds to compute gradient
0.005532264709472656  seconds to apply mask to gradient
0.6782341003417969  seconds to compute optimizer update
0.31219482421875  seconds to apply optimizer update
0.09034204483032227  seconds to pickle the checkpoint
step: 13 loss: 189.61102294921875
about to compute gradient
2205.656327724457  seconds to compute gradient
0.0066661834716796875  seconds to apply mask to gradient
0.6884162425994873  seconds to compute optimizer update
0.3160388469696045  seconds to apply optimizer update
0.0897665023803711  seconds to pickle the checkpoint
step: 14 loss: 189.21649169921875
about to compute gradient
2209.940738916397  seconds to compute gradient
0.006982088088989258  seconds to apply mask to gradient
0.6828546524047852  seconds to compute optimizer update
0.3109464645385742  seconds to apply optimizer update
0.1062309741973877  seconds to pickle the checkpoint
step: 15 loss: 189.0244140625
about to compute gradient
2605.804384469986  seconds to compute gradient
0.005983591079711914  seconds to apply mask to gradient
0.7077882289886475  seconds to compute optimizer update
0.33025503158569336  seconds to apply optimizer update
0.11232948303222656  seconds to pickle the checkpoint
step: 16 loss: 189.0150146484375
about to compute gradient
2317.3006110191345  seconds to compute gradient
0.005952358245849609  seconds to apply mask to gradient
0.7298071384429932  seconds to compute optimizer update
0.33646225929260254  seconds to apply optimizer update
0.11192774772644043  seconds to pickle the checkpoint
step: 17 loss: 189.13613891601562
about to compute gradient
2318.013795375824  seconds to compute gradient
0.006307840347290039  seconds to apply mask to gradient
0.7189674377441406  seconds to compute optimizer update
0.35384058952331543  seconds to apply optimizer update
0.09699440002441406  seconds to pickle the checkpoint
step: 18 loss: 189.31903076171875
about to compute gradient
2305.8252561092377  seconds to compute gradient
0.005992412567138672  seconds to apply mask to gradient
0.7069351673126221  seconds to compute optimizer update
0.31682705879211426  seconds to apply optimizer update
0.10744380950927734  seconds to pickle the checkpoint
step: 19 loss: 189.49118041992188
about to compute gradient
2253.5790779590607  seconds to compute gradient
0.003952503204345703  seconds to apply mask to gradient
0.6838769912719727  seconds to compute optimizer update
0.31275510787963867  seconds to apply optimizer update
0.10853910446166992  seconds to pickle the checkpoint
step: 20 loss: 189.59567260742188
about to compute gradient
2254.4310183525085  seconds to compute gradient
0.005982875823974609  seconds to apply mask to gradient
0.6956682205200195  seconds to compute optimizer update
0.3143129348754883  seconds to apply optimizer update
0.09146547317504883  seconds to pickle the checkpoint
step: 21 loss: 189.59974670410156
about to compute gradient
2270.346997976303  seconds to compute gradient
0.005948066711425781  seconds to apply mask to gradient
0.7103245258331299  seconds to compute optimizer update
0.32137012481689453  seconds to apply optimizer update
0.10161566734313965  seconds to pickle the checkpoint
step: 22 loss: 189.5023956298828
about to compute gradient
2253.4603774547577  seconds to compute gradient
0.005959510803222656  seconds to apply mask to gradient
0.779522180557251  seconds to compute optimizer update
0.33847546577453613  seconds to apply optimizer update
0.10646796226501465  seconds to pickle the checkpoint
step: 23 loss: 189.340576171875
about to compute gradient
2302.4618599414825  seconds to compute gradient
0.00457453727722168  seconds to apply mask to gradient
0.7061448097229004  seconds to compute optimizer update
0.31797099113464355  seconds to apply optimizer update
0.09607505798339844  seconds to pickle the checkpoint
step: 24 loss: 189.13473510742188
about to compute gradient
2416.360837459564  seconds to compute gradient
0.007965087890625  seconds to apply mask to gradient
0.7714664936065674  seconds to compute optimizer update
0.42562294006347656  seconds to apply optimizer update
0.17594146728515625  seconds to pickle the checkpoint
step: 25 loss: 188.9228515625
about to compute gradient
2445.8672029972076  seconds to compute gradient
0.007432699203491211  seconds to apply mask to gradient
0.8002774715423584  seconds to compute optimizer update
0.3460080623626709  seconds to apply optimizer update
0.13182878494262695  seconds to pickle the checkpoint
step: 26 loss: 188.74095153808594
about to compute gradient
2569.37175822258  seconds to compute gradient
0.007027864456176758  seconds to apply mask to gradient
0.77996826171875  seconds to compute optimizer update
0.34830498695373535  seconds to apply optimizer update
0.15788674354553223  seconds to pickle the checkpoint
step: 27 loss: 188.6033935546875
about to compute gradient
2510.5490770339966  seconds to compute gradient
0.0059854984283447266  seconds to apply mask to gradient
0.7471251487731934  seconds to compute optimizer update
0.3329498767852783  seconds to apply optimizer update
0.14974617958068848  seconds to pickle the checkpoint
step: 28 loss: 188.51434326171875
about to compute gradient
2312.4290170669556  seconds to compute gradient
0.00698089599609375  seconds to apply mask to gradient
0.698544979095459  seconds to compute optimizer update
0.3175923824310303  seconds to apply optimizer update
0.09018993377685547  seconds to pickle the checkpoint
step: 29 loss: 188.4663543701172
>>>
```

This does not look like a good convergence, especially observing
that we are comparing with the first 30-40 iterations of this
run (with a lower learning rate): 

https://github.com/anhinga/julia-flux-drafts/tree/main/arxiv-1606-09470-section3/May-August-2022/v0-1/feedforward-run-3

But we also see from that log that one should not jump to conclusions,
Adam optimizer often finds a way. But here it does indeed look like it
is stuck in a local minimum.

We do need to start looking at adding regularization.
